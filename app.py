import streamlit as st
import os
import shutil
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.llms.groq import Groq
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from fpdf import FPDF
from pptx import Presentation
from pptx.util import Inches, Pt
import re

st.set_page_config(page_title="PolyVest AI - Funding Analyst", layout="wide")
st.title("PolyVest : Your AI Funding Companion !!")
st.markdown("Ask about **Funding Schemes**, or **Upload your own Document** for analysis.")

PERMANENT_DATA_PATH = "./data"
TEMP_UPLOAD_PATH = "./data/uploads"

os.makedirs(PERMANENT_DATA_PATH, exist_ok=True)
os.makedirs(TEMP_UPLOAD_PATH, exist_ok=True)

if "cleanup_done" not in st.session_state:
    for filename in os.listdir(TEMP_UPLOAD_PATH):
        file_path = os.path.join(TEMP_UPLOAD_PATH, filename)
        try:
            if os.path.isfile(file_path):
                os.unlink(file_path)
        except Exception as e:
            print(f"Error deleting {file_path}: {e}")
    st.session_state.cleanup_done = True

def generate_pdf(text):
    pdf = FPDF()
    pdf.add_page()
    
    pdf.set_font("Arial", 'B', 16)
    pdf.cell(0, 10, "PolyVest Funding Report", ln=True, align='C')
    pdf.ln(10)
    
    pdf.set_font("Arial", size=12)
    
    clean_text = text.replace("**", "").replace("##", "").replace("###", "")
    
    try:
        clean_text = clean_text.encode('latin-1', 'replace').decode('latin-1')
    except Exception:
        clean_text = "Error: Text contains unsupported characters."
        
    pdf.multi_cell(0, 8, clean_text)
    
    file_path = os.path.join(TEMP_UPLOAD_PATH, "Funding_Report.pdf")
    pdf.output(file_path)
    return file_path

def generate_ppt(text):
    prs = Presentation()
    slide_layout = prs.slide_layouts[0] 
    slide = prs.slides.add_slide(slide_layout)
    title = slide.shapes.title
    subtitle = slide.placeholders[1]
    title.text = "PolyVest Funding Report"
    subtitle.text = "Generated by AI Funding Companion"

    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    title = slide.shapes.title
    title.text = "Detailed Analysis"
    
    body_shape = slide.placeholders[1]
    tf = body_shape.text_frame
    clean_text = text.replace("**", "").replace("##", "")
    
    tf.text = clean_text[:1000] + "...\n(See PDF for full details)"
    
    file_path = os.path.join(TEMP_UPLOAD_PATH, "Funding_Report.pptx")
    prs.save(file_path)
    return file_path

st.sidebar.title("âš™ï¸ Settings")

if "GROQ_API_KEY" in st.secrets:
    api_key = st.secrets["GROQ_API_KEY"]
    st.sidebar.success("âœ… API Key loaded")
else:
    api_key = st.sidebar.text_input("Enter Groq API Key (gsk_...)", type="password")

if not api_key:
    st.warning("âš ï¸ Enter Groq API Key to start.")
    st.stop()

st.sidebar.markdown("---")
st.sidebar.subheader("ðŸ“‚ Analyze Your Doc")
st.sidebar.info("â„¹ï¸ Uploaded files are temporary and deleted on refresh.")
uploaded_file = st.sidebar.file_uploader("Upload Pitch Deck / Report", type=["pdf", "txt", "csv"])

if uploaded_file is not None:
    save_path = os.path.join(TEMP_UPLOAD_PATH, uploaded_file.name)
    with open(save_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    st.sidebar.success(f"âœ… Saved: {uploaded_file.name}")
    
    if st.sidebar.button("ðŸ”„ Process & Analyze Now"):
        st.cache_resource.clear()
        st.rerun()

try:
    Settings.llm = Groq(
        model="llama-3.3-70b-versatile", 
        api_key=api_key,
        context_window=8192,
        request_timeout=120.0
    )
    Settings.embed_model = HuggingFaceEmbedding(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        device="cpu"
    )
    Settings.chunk_size = 512       
    Settings.chunk_overlap = 50     

except Exception as e:
    st.error(f"System Error: {e}")
    st.stop()

@st.cache_resource(show_spinner=False)
def load_data():
    with st.spinner("ðŸ§  Reading Knowledge Base (Static DB + Temp Uploads)..."):
        documents = []
        if os.path.exists(PERMANENT_DATA_PATH):
            documents += SimpleDirectoryReader(PERMANENT_DATA_PATH, recursive=True).load_data()
        
        if not documents:
            return None
            
        index = VectorStoreIndex.from_documents(documents)
        return index

index = load_data()

if not index:
    st.info("ðŸ‘‹ Database empty. Add files to 'data' folder or upload one.")
    st.stop()

if "chat_engine" not in st.session_state:
    st.session_state.chat_engine = index.as_chat_engine(
        chat_mode="context",
        system_prompt=(
            "You are 'PolyVest', an expert Startup Consultant."
            "DATA SOURCES: You have access to official funding data AND user-uploaded documents."
            "INSTRUCTIONS:"
            "SPECIAL INSTRUCTION: If the user asks to 'Analyze' their uploaded pitch deck, DO NOT just summarize it."
            "Instead, generate a structured 'FUNDING READINESS REPORT' with:"
            "1. âœ… **Eligibility Check:** (Pass/Fail for SISFS based on age/sector)."
            "2. ðŸ’° **Valuation sanity check:** (Is their ask reasonable? Compare with your CSV data)."
            "3. ðŸŽ¯ **Investor Match:** (Name the top 3 specific investors from the database)."
            "4. ðŸ›‘ **Red Flags:** (What is missing? e.g., 'No revenue mentioned')."
            "5. ðŸ† **PolyVest Score:** Give a score out of 10 for funding probability."
            "IMPORTANT: Answer in the SAME language as the user. If they ask in English, answer in English."
        )
    )

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Ask: 'Give me a funding report pdf'"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            try:
                response = st.session_state.chat_engine.chat(prompt)
                ai_text = response.response
                st.markdown(ai_text)
                st.session_state.messages.append({"role": "assistant", "content": ai_text})
                
                trigger_words = ["pdf", "ppt", "download", "report", "file"]
                if any(word in prompt.lower() for word in trigger_words):
                
                    if len(ai_text) > 50: 
                        col1, col2 = st.columns(2)
                        
                        pdf_path = generate_pdf(ai_text)
                        with open(pdf_path, "rb") as f:
                            col1.download_button(
                                label="ðŸ“„ Download Report (PDF)",
                                data=f,
                                file_name="PolyVest_Report.pdf",
                                mime="application/pdf"
                            )

                        ppt_path = generate_ppt(ai_text)
                        with open(ppt_path, "rb") as f:
                            col2.download_button(
                                label="ðŸ“Š Download Slides (PPT)",
                                data=f,
                                file_name="PolyVest_Presentation.pptx",
                                mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
                            )

            except Exception as e:
                st.error(f"Error: {e}")